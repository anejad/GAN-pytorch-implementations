{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks (GAN) in Pytorch \n",
    "## Basic GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter \n",
    "from model import model_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 1.12.1, Torchvision Version: 0.13.1\n"
     ]
    }
   ],
   "source": [
    "print(f'Torch version: {torch.__version__}, Torchvision Version: {torchvision.__version__}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "lr = 3e-4\n",
    "z_dim = 64\n",
    "batch_size = 32\n",
    "num_epochs = 100\n",
    "im_dim=(28,28,1) #MNIST images are 28 x 28 x 1 (gray scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dataset Downloader - MNIST\n",
    "transforms = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,)),]\n",
    ")\n",
    "dataset = datasets.MNIST(root=\"../datasets/\", transform=transforms, download=True)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/100] Batch 0/1875                         Loss D: 0.6536, loss G: 0.7345\n",
      "Epoch [1/100] Batch 0/1875                         Loss D: 0.4770, loss G: 1.1080\n",
      "Epoch [2/100] Batch 0/1875                         Loss D: 0.6242, loss G: 0.7979\n",
      "Epoch [3/100] Batch 0/1875                         Loss D: 0.4127, loss G: 1.4874\n",
      "Epoch [4/100] Batch 0/1875                         Loss D: 0.8923, loss G: 0.6305\n",
      "Epoch [5/100] Batch 0/1875                         Loss D: 0.4737, loss G: 1.2038\n",
      "Epoch [6/100] Batch 0/1875                         Loss D: 0.3967, loss G: 1.6092\n",
      "Epoch [7/100] Batch 0/1875                         Loss D: 0.6761, loss G: 0.9314\n",
      "Epoch [8/100] Batch 0/1875                         Loss D: 0.5743, loss G: 1.3867\n",
      "Epoch [9/100] Batch 0/1875                         Loss D: 0.4765, loss G: 1.4884\n",
      "Epoch [10/100] Batch 0/1875                         Loss D: 0.5277, loss G: 1.4136\n",
      "Epoch [11/100] Batch 0/1875                         Loss D: 0.3262, loss G: 1.5427\n",
      "Epoch [12/100] Batch 0/1875                         Loss D: 0.6622, loss G: 1.2515\n",
      "Epoch [13/100] Batch 0/1875                         Loss D: 0.6620, loss G: 1.5539\n",
      "Epoch [14/100] Batch 0/1875                         Loss D: 0.4681, loss G: 1.5143\n",
      "Epoch [15/100] Batch 0/1875                         Loss D: 0.4967, loss G: 1.7258\n",
      "Epoch [16/100] Batch 0/1875                         Loss D: 0.5446, loss G: 1.7031\n",
      "Epoch [17/100] Batch 0/1875                         Loss D: 0.5338, loss G: 1.5796\n",
      "Epoch [18/100] Batch 0/1875                         Loss D: 0.4405, loss G: 1.9725\n",
      "Epoch [19/100] Batch 0/1875                         Loss D: 0.5034, loss G: 1.6938\n",
      "Epoch [20/100] Batch 0/1875                         Loss D: 0.5193, loss G: 1.5435\n",
      "Epoch [21/100] Batch 0/1875                         Loss D: 0.4386, loss G: 1.6077\n",
      "Epoch [22/100] Batch 0/1875                         Loss D: 0.7044, loss G: 1.3839\n",
      "Epoch [23/100] Batch 0/1875                         Loss D: 0.6680, loss G: 1.2561\n",
      "Epoch [24/100] Batch 0/1875                         Loss D: 0.8226, loss G: 1.0852\n",
      "Epoch [25/100] Batch 0/1875                         Loss D: 0.4486, loss G: 1.3485\n",
      "Epoch [26/100] Batch 0/1875                         Loss D: 0.5757, loss G: 1.3236\n",
      "Epoch [27/100] Batch 0/1875                         Loss D: 0.5070, loss G: 1.4610\n",
      "Epoch [28/100] Batch 0/1875                         Loss D: 0.6149, loss G: 1.7388\n",
      "Epoch [29/100] Batch 0/1875                         Loss D: 0.6622, loss G: 1.2228\n",
      "Epoch [30/100] Batch 0/1875                         Loss D: 0.5387, loss G: 1.6144\n",
      "Epoch [31/100] Batch 0/1875                         Loss D: 0.4859, loss G: 1.8826\n",
      "Epoch [32/100] Batch 0/1875                         Loss D: 0.4967, loss G: 1.5015\n",
      "Epoch [33/100] Batch 0/1875                         Loss D: 0.6407, loss G: 1.2171\n",
      "Epoch [34/100] Batch 0/1875                         Loss D: 0.6077, loss G: 1.5261\n",
      "Epoch [35/100] Batch 0/1875                         Loss D: 0.4938, loss G: 1.7636\n",
      "Epoch [36/100] Batch 0/1875                         Loss D: 0.6311, loss G: 1.4885\n",
      "Epoch [37/100] Batch 0/1875                         Loss D: 0.6185, loss G: 1.5883\n",
      "Epoch [38/100] Batch 0/1875                         Loss D: 0.4727, loss G: 1.6863\n",
      "Epoch [39/100] Batch 0/1875                         Loss D: 0.5551, loss G: 1.2919\n",
      "Epoch [40/100] Batch 0/1875                         Loss D: 0.5797, loss G: 1.6790\n",
      "Epoch [41/100] Batch 0/1875                         Loss D: 0.5366, loss G: 1.4246\n",
      "Epoch [42/100] Batch 0/1875                         Loss D: 0.3706, loss G: 2.1469\n",
      "Epoch [43/100] Batch 0/1875                         Loss D: 0.6168, loss G: 1.1816\n",
      "Epoch [44/100] Batch 0/1875                         Loss D: 0.5154, loss G: 1.4330\n",
      "Epoch [45/100] Batch 0/1875                         Loss D: 0.3996, loss G: 1.4379\n",
      "Epoch [46/100] Batch 0/1875                         Loss D: 0.5947, loss G: 1.0606\n",
      "Epoch [47/100] Batch 0/1875                         Loss D: 0.6116, loss G: 1.1223\n",
      "Epoch [48/100] Batch 0/1875                         Loss D: 0.4460, loss G: 1.1640\n",
      "Epoch [49/100] Batch 0/1875                         Loss D: 0.6912, loss G: 1.2256\n",
      "Epoch [50/100] Batch 0/1875                         Loss D: 0.6787, loss G: 0.9520\n",
      "Epoch [51/100] Batch 0/1875                         Loss D: 0.6190, loss G: 1.1681\n",
      "Epoch [52/100] Batch 0/1875                         Loss D: 0.5121, loss G: 1.1701\n",
      "Epoch [53/100] Batch 0/1875                         Loss D: 0.6432, loss G: 1.0180\n",
      "Epoch [54/100] Batch 0/1875                         Loss D: 0.5911, loss G: 1.2344\n",
      "Epoch [55/100] Batch 0/1875                         Loss D: 0.5960, loss G: 1.1531\n",
      "Epoch [56/100] Batch 0/1875                         Loss D: 0.5778, loss G: 0.9594\n",
      "Epoch [57/100] Batch 0/1875                         Loss D: 0.4285, loss G: 1.3524\n",
      "Epoch [58/100] Batch 0/1875                         Loss D: 0.6603, loss G: 1.0118\n",
      "Epoch [59/100] Batch 0/1875                         Loss D: 0.5516, loss G: 1.2629\n",
      "Epoch [60/100] Batch 0/1875                         Loss D: 0.6825, loss G: 0.7469\n",
      "Epoch [61/100] Batch 0/1875                         Loss D: 0.6849, loss G: 1.0143\n",
      "Epoch [62/100] Batch 0/1875                         Loss D: 0.6690, loss G: 0.7483\n",
      "Epoch [63/100] Batch 0/1875                         Loss D: 0.4960, loss G: 1.1582\n",
      "Epoch [64/100] Batch 0/1875                         Loss D: 0.7370, loss G: 0.8920\n",
      "Epoch [65/100] Batch 0/1875                         Loss D: 0.6196, loss G: 0.9589\n",
      "Epoch [66/100] Batch 0/1875                         Loss D: 0.6712, loss G: 0.9027\n",
      "Epoch [67/100] Batch 0/1875                         Loss D: 0.7526, loss G: 0.8994\n",
      "Epoch [68/100] Batch 0/1875                         Loss D: 0.6712, loss G: 0.7827\n",
      "Epoch [69/100] Batch 0/1875                         Loss D: 0.6705, loss G: 1.0737\n",
      "Epoch [70/100] Batch 0/1875                         Loss D: 0.6358, loss G: 0.8216\n",
      "Epoch [71/100] Batch 0/1875                         Loss D: 0.6051, loss G: 1.1983\n",
      "Epoch [72/100] Batch 0/1875                         Loss D: 0.6036, loss G: 1.1357\n",
      "Epoch [73/100] Batch 0/1875                         Loss D: 0.5846, loss G: 0.9920\n",
      "Epoch [74/100] Batch 0/1875                         Loss D: 0.6070, loss G: 0.8615\n",
      "Epoch [75/100] Batch 0/1875                         Loss D: 0.6489, loss G: 0.8733\n",
      "Epoch [76/100] Batch 0/1875                         Loss D: 0.6340, loss G: 0.7149\n",
      "Epoch [77/100] Batch 0/1875                         Loss D: 0.6512, loss G: 1.1846\n",
      "Epoch [78/100] Batch 0/1875                         Loss D: 0.6060, loss G: 0.9580\n",
      "Epoch [79/100] Batch 0/1875                         Loss D: 0.5278, loss G: 0.9131\n",
      "Epoch [80/100] Batch 0/1875                         Loss D: 0.5644, loss G: 0.9960\n",
      "Epoch [81/100] Batch 0/1875                         Loss D: 0.5078, loss G: 1.0099\n",
      "Epoch [82/100] Batch 0/1875                         Loss D: 0.7015, loss G: 0.7543\n",
      "Epoch [83/100] Batch 0/1875                         Loss D: 0.6229, loss G: 0.7178\n",
      "Epoch [84/100] Batch 0/1875                         Loss D: 0.6401, loss G: 0.8523\n",
      "Epoch [85/100] Batch 0/1875                         Loss D: 0.5329, loss G: 1.0019\n",
      "Epoch [86/100] Batch 0/1875                         Loss D: 0.6192, loss G: 0.9972\n",
      "Epoch [87/100] Batch 0/1875                         Loss D: 0.5983, loss G: 0.9792\n",
      "Epoch [88/100] Batch 0/1875                         Loss D: 0.5884, loss G: 0.8756\n",
      "Epoch [89/100] Batch 0/1875                         Loss D: 0.7233, loss G: 0.8715\n",
      "Epoch [90/100] Batch 0/1875                         Loss D: 0.6927, loss G: 0.8722\n",
      "Epoch [91/100] Batch 0/1875                         Loss D: 0.6139, loss G: 0.8783\n",
      "Epoch [92/100] Batch 0/1875                         Loss D: 0.5467, loss G: 1.1482\n",
      "Epoch [93/100] Batch 0/1875                         Loss D: 0.5965, loss G: 0.8531\n",
      "Epoch [94/100] Batch 0/1875                         Loss D: 0.5955, loss G: 0.8834\n",
      "Epoch [95/100] Batch 0/1875                         Loss D: 0.6300, loss G: 0.8877\n",
      "Epoch [96/100] Batch 0/1875                         Loss D: 0.6452, loss G: 0.9460\n",
      "Epoch [97/100] Batch 0/1875                         Loss D: 0.6886, loss G: 1.0296\n",
      "Epoch [98/100] Batch 0/1875                         Loss D: 0.5825, loss G: 1.1833\n",
      "Epoch [99/100] Batch 0/1875                         Loss D: 0.5359, loss G: 0.9650\n"
     ]
    }
   ],
   "source": [
    "model_trainer(loader,lr, im_dim,z_dim,num_epochs,batch_size,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7f7975df2161d56d305ba3d5b72a242dfdc77f800d8a30af34c77c8a11a798a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
